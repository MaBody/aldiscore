{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "4c3937aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pathlib\n",
    "from aldiscore.scoring import confusion\n",
    "from aldiscore.datastructures.alignment import Alignment\n",
    "from aldiscore.datastructures.ensemble import Ensemble\n",
    "import os\n",
    "from Bio.Align import MultipleSeqAlignment\n",
    "from Bio.AlignIO import read"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "cf728f66",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ensemble of 4 alignments.\n",
      "14 sequences of lengths between 329 and 465.\n",
      "Alignment dimensions: [(14, 764), (14, 806), (14, 774), (14, 774)]\n"
     ]
    }
   ],
   "source": [
    "TEST_DATA_DIR = pathlib.Path.cwd().parent / \"tests\" / \"data\"\n",
    "\n",
    "_alignments: list[Alignment] = []\n",
    "\n",
    "for msa_file in os.listdir(TEST_DATA_DIR):\n",
    "    if msa_file.startswith(\"protein\"):\n",
    "        msa: MultipleSeqAlignment = read(TEST_DATA_DIR / msa_file, \"fasta\")\n",
    "        _alignment = Alignment(msa=msa, sort_sequences=True)\n",
    "        _alignments.append(_alignment)\n",
    "_dataset = _alignment.get_dataset()\n",
    "_ensemble = Ensemble(_alignments, _dataset)\n",
    "\n",
    "\n",
    "num_seqs = len(_ensemble.dataset.records)\n",
    "min_seq_length = min(_ensemble.dataset._sequence_lengths)\n",
    "max_seq_length = max(_ensemble.dataset._sequence_lengths)\n",
    "alignment_shapes = [a.shape for a in _ensemble.alignments]\n",
    "print(f\"Ensemble of {len(_ensemble.alignments)} alignments.\")\n",
    "print(f\"{num_seqs} sequences of lengths between {min_seq_length} and {max_seq_length}.\")\n",
    "print(f\"Alignment dimensions: {alignment_shapes}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7631bb40",
   "metadata": {},
   "source": [
    "**Compute three variants of the confusion score**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "a5aa85b4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ConfSet: 0.33005356043693557\n",
      "ConfEntropy: 0.3742146871758933\n",
      "ConfDisplace: 0.12681854154444624\n"
     ]
    }
   ],
   "source": [
    "metric = confusion.ConfusionSet(aggregate=\"site\")\n",
    "score = metric.compute(_ensemble)\n",
    "print(\"ConfSet:\", score)\n",
    "\n",
    "metric = confusion.ConfusionEntropy(aggregate=\"site\")\n",
    "score = metric.compute(_ensemble)\n",
    "print(\"ConfEntropy:\", score)\n",
    "\n",
    "metric = confusion.ConfusionDisplace(aggregate=\"site\")\n",
    "score = metric.compute(_ensemble)\n",
    "print(\"ConfDisplace:\", score)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1549824c",
   "metadata": {},
   "source": [
    "**Compute ConfEntropy in three levels of aggregation**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "3fa658cc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overall mean\n",
      "0.3742146871758933\n",
      "\n",
      "Mean per sequence\n",
      "[0.4851988  0.49368874 0.2950834  0.36375336 0.32025744 0.33836156\n",
      " 0.35935771 0.3025806  0.28247488 0.40750361 0.32739424 0.42480393\n",
      " 0.38748052 0.38967909]\n",
      "\n",
      "Residue-level scores\n",
      "[0.         0.06240601 0.2547137  0.53808558 0.70899363 0.91581839\n",
      " 0.7547137  0.87735685 0.89658762 0.89658762 0.89658762 0.89658762\n",
      " 0.92307692 0.94230769 0.94230769 0.94230769 0.94230769 0.96153846\n",
      " 0.96153846 0.86538462 0.88461538 0.94230769 0.96153846 0.98076923\n",
      " 0.98076923 0.98076923 0.98076923 0.98076923 0.98076923 0.94230769\n",
      " 0.92307692 0.88461538 0.96153846 0.96153846 0.96153846 0.96153846\n",
      " 0.98076923 0.94230769 0.86538462 0.60558125]\n",
      "...\n"
     ]
    }
   ],
   "source": [
    "metric = confusion.ConfusionEntropy(aggregate=\"site\")\n",
    "score = metric.compute(_ensemble)\n",
    "print(\"Overall mean\")\n",
    "print(score)\n",
    "print()\n",
    "\n",
    "metric = confusion.ConfusionEntropy(aggregate=\"sequence\")\n",
    "scores = metric.compute(_ensemble)\n",
    "print(\"Mean per sequence\")\n",
    "print(scores)\n",
    "print()\n",
    "\n",
    "metric = confusion.ConfusionEntropy()\n",
    "scores = metric.compute(_ensemble)\n",
    "print(\"Residue-level scores\")\n",
    "print(scores[0][:40])\n",
    "print(\"...\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "aldiscore",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
