{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "4c3937aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pathlib\n",
    "import numpy as np\n",
    "from Bio.AlignIO import read\n",
    "from Bio.Align import MultipleSeqAlignment\n",
    "from aldiscore.scoring import pairwise\n",
    "from aldiscore.scoring import set_based\n",
    "from aldiscore.datastructures.ensemble import Ensemble\n",
    "from aldiscore.datastructures.alignment import Alignment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "cf728f66",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ensemble of 4 alignments.\n",
      "14 sequences of lengths between 329 and 465.\n",
      "Alignment dimensions: [(14, 764), (14, 806), (14, 774), (14, 774)]\n"
     ]
    }
   ],
   "source": [
    "TEST_DATA_DIR = pathlib.Path.cwd() / \"data\"\n",
    "\n",
    "_alignments: list[Alignment] = []\n",
    "\n",
    "for msa_file in os.listdir(TEST_DATA_DIR):\n",
    "    if msa_file.startswith(\"protein\"):\n",
    "        msa = read(TEST_DATA_DIR / msa_file, \"fasta\")\n",
    "        _alignment = Alignment(msa=msa, sort_sequences=True)\n",
    "        _alignments.append(_alignment)\n",
    "_ensemble = Ensemble(_alignments)\n",
    "\n",
    "\n",
    "num_seqs = len(_ensemble.dataset.records)\n",
    "min_seq_length = min(_ensemble.dataset._sequence_lengths)\n",
    "max_seq_length = max(_ensemble.dataset._sequence_lengths)\n",
    "alignment_shapes = [a.shape for a in _ensemble.alignments]\n",
    "print(f\"Ensemble of {len(_ensemble.alignments)} alignments.\")\n",
    "print(f\"{num_seqs} sequences of lengths between {min_seq_length} and {max_seq_length}.\")\n",
    "print(f\"Alignment dimensions: {alignment_shapes}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7631bb40",
   "metadata": {},
   "source": [
    "**Compute aggregated confusion scores**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a5aa85b4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ConfSet: 0.33005356043693557\n",
      "ConfEntropy: 0.3742146871758933\n",
      "ConfDisplace: 0.12681854154444624\n"
     ]
    }
   ],
   "source": [
    "measure = set_based.ConfusionSet(aggregate=\"site\")\n",
    "score = measure.compute(_ensemble)\n",
    "print(\"ConfSet:\", score)\n",
    "\n",
    "measure = set_based.ConfusionEntropy(aggregate=\"site\")\n",
    "score = measure.compute(_ensemble)\n",
    "print(\"ConfEntropy:\", score)\n",
    "\n",
    "measure = set_based.ConfusionDisplace(aggregate=\"site\")\n",
    "score = measure.compute(_ensemble)\n",
    "print(\"ConfDisplace:\", score)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1549824c",
   "metadata": {},
   "source": [
    "**Compute ConfEntropy in three levels of aggregation**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "3fa658cc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overall mean\n",
      "0.3742146871758933\n",
      "\n",
      "Mean per sequence\n",
      "[0.4851988  0.49368874 0.2950834  0.36375336 0.32025744 0.33836156\n",
      " 0.35935771 0.3025806  0.28247488 0.40750361 0.32739424 0.42480393\n",
      " 0.38748052 0.38967909]\n",
      "\n",
      "Residue-level scores\n",
      "[0.         0.06240601 0.2547137  0.53808558 0.70899363 0.91581839\n",
      " 0.7547137  0.87735685 0.89658762 0.89658762 0.89658762 0.89658762\n",
      " 0.92307692 0.94230769 0.94230769 0.94230769 0.94230769 0.96153846\n",
      " 0.96153846 0.86538462 0.88461538 0.94230769 0.96153846 0.98076923]\n",
      "...\n"
     ]
    }
   ],
   "source": [
    "measure = set_based.ConfusionEntropy(aggregate=\"site\")\n",
    "score = measure.compute(_ensemble)\n",
    "print(\"Overall mean\")\n",
    "print(score)\n",
    "print()\n",
    "\n",
    "measure = set_based.ConfusionEntropy(aggregate=\"sequence\")\n",
    "scores = measure.compute(_ensemble)\n",
    "print(\"Mean per sequence\")\n",
    "print(scores)\n",
    "print()\n",
    "\n",
    "measure = set_based.ConfusionEntropy(aggregate=None)\n",
    "scores = measure.compute(_ensemble)\n",
    "print(\"Residue-level scores\")\n",
    "print(scores[0][:24])\n",
    "print(\"...\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2cb677fa",
   "metadata": {},
   "source": [
    "**Compute aggregated pairwise scores**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "098abbaf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "d_SSP: 0.4973944949996321\n",
      "d_seq: 0.3485447730342033\n",
      "d_pos: 0.42303328464202705\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "pHash: 0.2775297619047619\n"
     ]
    }
   ],
   "source": [
    "measure = pairwise.SSPDistance()\n",
    "score = measure.compute(_ensemble).mean()\n",
    "print(\"d_SSP:\", score)\n",
    "measure = pairwise.DSeqDistance()\n",
    "score = measure.compute(_ensemble).mean()\n",
    "print(\"d_seq:\", score)\n",
    "measure = pairwise.DPosDistance()\n",
    "score = measure.compute(_ensemble).mean()\n",
    "print(\"d_pos:\", score)\n",
    "measure = pairwise.PHashDistance()\n",
    "score = measure.compute(_ensemble).mean()\n",
    "print(\"pHash:\", score)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "973e4c71",
   "metadata": {},
   "source": [
    "**Compute distance matrix for d_pos**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "ff6f3132",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "distance matrix\n",
      "[[0.   0.43 0.3  0.47]\n",
      " [0.43 0.   0.39 0.48]\n",
      " [0.3  0.39 0.   0.47]\n",
      " [0.47 0.48 0.47 0.  ]]\n"
     ]
    }
   ],
   "source": [
    "measure = pairwise.DPosDistance()\n",
    "score = measure.compute(_ensemble, format=\"matrix\")\n",
    "print(\"distance matrix\")\n",
    "print(score.round(2))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "aldiscore",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
